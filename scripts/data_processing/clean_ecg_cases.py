# clean_ecg_cases.py
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∫–µ–π—Å–æ–≤ –∏–∑ Dr. Smith's ECG Blog.
–£–¥–∞–ª—è–µ—Ç –Ω–∞–≤–∏–≥–∞—Ü–∏—é, –¥–∞—Ç—ã, —Å—Å—ã–ª–∫–∏, —Ä–µ–∫–ª–∞–º—É, –ø–æ–¥–ø–∏—Å–∫—É –∏ –ø—Ä–æ—á–∏–π –º—É—Å–æ—Ä.
"""

import re
from pathlib import Path
import json
from typing import List, Tuple

def clean_ecg_case_content(content: str) -> str:
    """
    –û—á–∏—â–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –∫–µ–π—Å–∞ ECG –±–ª–æ–≥–∞, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –º–µ–¥–∏—Ü–∏–Ω—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
    """
    original_length = len(content)
    
    # 1. –£–¥–∞–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü —Å –¥–∞—Ç–∞–º–∏ –∏ URL
    page_patterns = [
        # --- –°—Ç—Ä–∞–Ω–∏—Ü–∞ X --- —Å –¥–∞—Ç–æ–π –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ–º
        r'--- –°—Ç—Ä–∞–Ω–∏—Ü–∞ \d+ ---\s*\n\d{2}/\d{2}/\d{4}, \d{2}:\d{2}.*?- Dr\. Smith‚Äôs ECG Blog\s*\n',
        # –ü—Ä–æ—Å—Ç–æ --- –°—Ç—Ä–∞–Ω–∏—Ü–∞ X ---
        r'--- –°—Ç—Ä–∞–Ω–∏—Ü–∞ \d+ ---\s*\n',
        # –î–∞—Ç–∞ –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏
        r'\d{2}/\d{2}/\d{4}, \d{2}:\d{2}.*?- Dr\. Smith‚Äôs ECG Blog',
        # URL –≤ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏
        r'https://drsmithsecgblog\.com/.*?/\d+/\d+\s*\n',
    ]
    
    for pattern in page_patterns:
        content = re.sub(pattern, '', content, flags=re.IGNORECASE)
    
    # 2. –£–¥–∞–ª—è–µ–º –Ω–∞–≤–∏–≥–∞—Ü–∏—é –∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –±–ª–æ–≥–∞
    navigation_patterns = [
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –±–ª–æ–≥–∞ –∏ —Ä–µ–¥–∞–∫—Ç–æ—Ä—ã
        r'Dr\. Smith\'s ECG Blog\s*\nInstructive ECGs in Emergency Medicine Clinical Content\s*\n'
        r'Associate Editors:.*?Home.*?\n',
        # –í—Å—ë –æ—Ç "Home" –¥–æ –Ω–∞—á–∞–ª–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        r'Home.*?\n(?:.*?\n){0,3}',
    ]
    
    for pattern in navigation_patterns:
        content = re.sub(pattern, '', content, flags=re.DOTALL | re.IGNORECASE)
    
    # 3. –£–¥–∞–ª—è–µ–º –±–ª–æ–∫ "Write a Comment" –∏ –≤—Å—ë —á—Ç–æ –ø–æ—Å–ª–µ
    if 'Write a Comment' in content:
        comment_start = content.find('Write a Comment')
        if comment_start > 0:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–æ –∫–æ–º–º–µ–Ω—Ç–∞
            before_comment = content[:comment_start]
            medical_keywords = ['ECG', 'chest pain', 'patient', 'diagnosis', 'treatment', 'STEMI', 'OMI']
            
            if any(keyword.lower() in before_comment.lower() for keyword in medical_keywords):
                content = before_comment.strip()
    
    # 4. –£–¥–∞–ª—è–µ–º –±–ª–æ–∫ ABOUT –∏ –≤—Å—ë —á—Ç–æ –≤ –Ω—ë–º
    about_patterns = [
        r'ABOUT.*?FOLLOW US ON X \(TWITTER\).*?(?=\n\n|\Z)',
        r'FOLLOW US ON X \(TWITTER\).*?FEATURED POSTS.*?(?=\n\n|\Z)',
        r'FEATURED POSTS.*?BLOG ARCHIVE.*?(?=\n\n|\Z)',
        r'BLOG ARCHIVE.*?Select Month.*?(?=\n\n|\Z)',
        r'LABELS.*?Read Next.*?(?=\n\n|\Z)',
        r'Read Next.*?Never Miss a Beat.*?(?=\n\n|\Z)',
        r'Never Miss a Beat.*?Expert ECG Interpretation.*?(?=\n\n|\Z)',
        r'¬© \d{4} ‚Äî Dr\. Smith\'s ECG Blog\..*?(?=\n\n|\Z)',
        # –õ–∏—Ü–µ–Ω–∑–∏—è
        r'This work is licensed under.*?International License\.',
        # –°—Å—ã–ª–∫–∏ –Ω–∞ —Å–æ—Ü—Å–µ—Ç–∏
        r'Follow @\w+\s*',
    ]
    
    for pattern in about_patterns:
        content = re.sub(pattern, '', content, flags=re.DOTALL | re.IGNORECASE)
    
    # 5. –£–¥–∞–ª—è–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å —Ä–µ–∫–ª–∞–º–æ–π/—Å—Å—ã–ª–∫–∞–º–∏
    trash_lines = [
        'Trusted insights, no spam‚Äîonly ECG brilliance.',
        'Expert ECG Interpretation and Emergency Cardiology Education',
        'Get the latest expert ECG cases, clinical pearls, and interpretation tips',
        'Email Address Subscribe',
        'Dr. Smith\'s Google Scholar Profile',
        'Dr. Smith Articles on PubMed',
        'FACULTY PHYSICIAN',
        r'Written by .*? on.*?\d{4}',
        r'This was written by .*?\..*?\n',
        r'This was sent by .*?\..*?\n',
    ]
    
    for line_pattern in trash_lines:
        content = re.sub(line_pattern + r'.*?\n', '', content, flags=re.IGNORECASE)
    
    # 6. –£–¥–∞–ª—è–µ–º –º–µ—Ç–∫–∏-—Ç–µ–≥–∏ (–≤—Å—ë –≤ –∫–∞–≤—ã—á–∫–∞—Ö —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª)
    # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ—Å—Ç–æ—è—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –∏–∑ —Ç–µ–≥–æ–≤ –≤ –∫–∞–≤—ã—á–∫–∞—Ö
    lines = content.split('\n')
    cleaned_lines = []
    
    for line in lines:
        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –º–Ω–æ–≥–æ —Ç–µ–≥–æ–≤ –≤ –∫–∞–≤—ã—á–∫–∞—Ö - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        if line.count('"') >= 4:  # –ú–Ω–æ–≥–æ –∫–∞–≤—ã—á–µ–∫ = –≤–µ—Ä–æ—è—Ç–Ω–æ —Ç–µ–≥–∏
            # –ù–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ –≤ —Å—Ç—Ä–æ–∫–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            medical_indicators = ['ECG', 'pain', 'patient', 'heart', 'chest', 'diagnos', 'treat']
            if not any(indicator.lower() in line.lower() for indicator in medical_indicators):
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç—É —Å—Ç—Ä–æ–∫—É
        cleaned_lines.append(line)
    
    content = '\n'.join(cleaned_lines)
    
    # 7. –£–¥–∞–ª—è–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞-—Ç–µ–≥–∏
    tag_pattern = r'\"[^\"]+\"\(?\d*\)?\s*'
    content = re.sub(tag_pattern, '', content)
    
    # 8. –û—á–∏—â–∞–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    content = re.sub(r'\n{3,}', '\n\n', content)  # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã
    content = re.sub(r'[ \t]{2,}', ' ', content)  # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
    content = content.strip()
    
    # 9. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —É–¥–∞–ª–∏–ª–∏ –ª–∏ –≤–µ—Å—å –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç
    medical_keywords = ['ECG', 'patient', 'chest', 'pain', 'heart', 'diagnosis', 
                       'treatment', 'history', 'symptoms', 'findings', 'case']
    
    has_medical_content = any(keyword.lower() in content.lower() for keyword in medical_keywords)
    
    if not has_medical_content or len(content) < 100:
        print(f"  ‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –≤–æ–∑–º–æ–∂–Ω–æ —É–¥–∞–ª—ë–Ω –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç")
        print(f"     –î–ª–∏–Ω–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
        return None  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º None —á—Ç–æ–±—ã –æ—Å—Ç–∞–≤–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª
    
    cleaned_length = len(content)
    print(f"  –û—á–∏—â–µ–Ω–æ: {original_length} ‚Üí {cleaned_length} chars ({cleaned_length/original_length*100:.1f}%)")
    
    return content

def process_ecg_case_file(file_path: Path) -> Tuple[bool, int, int]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª –∫–µ–π—Å–∞ ECG.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (—É—Å–ø–µ—Ö, –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è_–¥–ª–∏–Ω–∞, –æ—á–∏—â–µ–Ω–Ω–∞—è_–¥–ª–∏–Ω–∞)
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            full_content = f.read()
        
        if '=== –°–û–î–ï–†–ñ–ê–ù–ò–ï ===' not in full_content:
            return False, 0, 0
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ –∫–æ–Ω—Ç–µ–Ω—Ç
        metadata_part, case_content = full_content.split('=== –°–û–î–ï–†–ñ–ê–ù–ò–ï ===', 1)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —ç—Ç–æ –ª–∏ –∫–µ–π—Å ECG –±–ª–æ–≥–∞
        is_ecg_case = any(keyword in full_content for keyword in 
                         ['Dr. Smith', 'ECG Blog', 'chest pain', 'ECG'])
        
        if not is_ecg_case:
            return False, 0, 0
        
        print(f"\nüìã –û–±—Ä–∞–±–æ—Ç–∫–∞: {file_path.name}")
        
        # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
        cleaned_content = clean_ecg_case_content(case_content)
        
        if cleaned_content is None:
            print(f"  ‚ùå –§–∞–π–ª –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
            return False, len(case_content), 0
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∞–π–ª
        new_content = metadata_part + '=== –°–û–î–ï–†–ñ–ê–ù–ò–ï ===\n' + cleaned_content
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        return True, len(case_content), len(cleaned_content)
        
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {file_path.name}: {str(e)}")
        return False, 0, 0

def analyze_case_file(file_path: Path) -> dict:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –∫–µ–π—Å–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏.
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    if '=== –°–û–î–ï–†–ñ–ê–ù–ò–ï ===' in content:
        _, case_content = content.split('=== –°–û–î–ï–†–ñ–ê–ù–ò–ï ===', 1)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º—É—Å–æ—Ä–∞
        trash_patterns = {
            '—Å—Ç—Ä–∞–Ω–∏—Ü—ã': r'--- –°—Ç—Ä–∞–Ω–∏—Ü–∞ \d+ ---',
            '–¥–∞—Ç—ã': r'\d{2}/\d{2}/\d{4}, \d{2}:\d{2}',
            'url': r'https://drsmithsecgblog\.com',
            '–Ω–∞–≤–∏–≥–∞—Ü–∏—è': r'Dr\. Smith\'s ECG Blog',
            '—Ç–µ–≥–∏': r'LABELS',
            '—Ä–µ–∫–ª–∞–º–∞': r'Never Miss a Beat',
            '–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏': r'Write a Comment',
        }
        
        trash_counts = {}
        for name, pattern in trash_patterns.items():
            matches = len(re.findall(pattern, case_content, re.IGNORECASE))
            trash_counts[name] = matches
        
        # –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç
        medical_keywords = ['ECG', 'chest pain', 'patient', 'diagnosis', 'STEMI', 'OMI', 'angina']
        medical_count = sum(1 for kw in medical_keywords if kw.lower() in case_content.lower())
        
        return {
            'file': file_path.name,
            'total_length': len(case_content),
            'trash_patterns': trash_counts,
            'medical_keywords': medical_count,
            'has_ecg_blog': 'Dr. Smith' in case_content or 'ECG Blog' in case_content,
        }
    return {}

def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—á–∏—Å—Ç–∫–∏ –∫–µ–π—Å–æ–≤ ECG.
    """
    cases_path = Path("data/processed/cardiology/Cases")
    
    if not cases_path.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ Cases –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {cases_path}")
        return
    
    # 1. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
    print("üîç –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤ –∫–µ–π—Å–æ–≤...")
    txt_files = list(cases_path.glob("*.txt"))
    print(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(txt_files)}")
    
    ecg_cases = []
    other_cases = []
    
    for file_path in txt_files[:10]:  # –ü–µ—Ä–≤—ã–µ 10 –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        analysis = analyze_case_file(file_path)
        if analysis:
            if analysis['has_ecg_blog']:
                ecg_cases.append(analysis)
            else:
                other_cases.append(analysis)
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ (–ø–µ—Ä–≤—ã–µ 10 —Ñ–∞–π–ª–æ–≤):")
    print(f"‚úÖ –ö–µ–π—Å—ã Dr. Smith's ECG Blog: {len(ecg_cases)}")
    print(f"üìÑ –î—Ä—É–≥–∏–µ –∫–µ–π—Å—ã: {len(other_cases)}")
    
    if ecg_cases:
        print("\n–û–±—Ä–∞–∑–µ—Ü –º—É—Å–æ—Ä–∞ –≤ ECG –∫–µ–π—Å–∞—Ö:")
        for pattern, count in ecg_cases[0]['trash_patterns'].items():
            if count > 0:
                print(f"  - {pattern}: {count}")
    
    # 2. –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –æ—á–∏—Å—Ç–∫–∏
    print(f"\n{'='*60}")
    print("–û–ß–ò–°–¢–ö–ê –ö–ï–ô–°–û–í DR. SMITH'S ECG BLOG")
    print("="*60)
    print("–ë—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ:")
    print("  ‚Ä¢ –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü (--- –°—Ç—Ä–∞–Ω–∏—Ü–∞ X ---)")
    print("  ‚Ä¢ –î–∞—Ç—ã –∏ URL")
    print("  ‚Ä¢ –ù–∞–≤–∏–≥–∞—Ü–∏—è –±–ª–æ–≥–∞")
    print("  ‚Ä¢ –ë–ª–æ–∫ ABOUT –∏ —Ä–µ–∫–ª–∞–º–∞")
    print("  ‚Ä¢ –¢–µ–≥–∏ (LABELS)")
    print("  ‚Ä¢ –§–æ—Ä–º–∞ –ø–æ–¥–ø–∏—Å–∫–∏")
    print("  ‚Ä¢ –§—É—Ç–µ—Ä —Å –∫–æ–ø–∏—Ä–∞–π—Ç–æ–º")
    
    response = input("\n–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ—á–∏—Å—Ç–∫—É? (y/n): ").lower()
    if response != 'y':
        print("–û—á–∏—Å—Ç–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞.")
        return
    
    # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
    print(f"\nüîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(txt_files)} —Ñ–∞–π–ª–æ–≤...")
    
    total_original = 0
    total_cleaned = 0
    processed_count = 0
    
    for file_path in txt_files:
        success, orig_len, cleaned_len = process_ecg_case_file(file_path)
        if success:
            total_original += orig_len
            total_cleaned += cleaned_len
            processed_count += 1
    
    # 4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\n{'='*60}")
    print("üìä –ò–¢–û–ì–ò –û–ß–ò–°–¢–ö–ò")
    print("="*60)
    print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {processed_count}/{len(txt_files)}")
    print(f"–û–±—â–∏–π –æ–±—ä—ë–º:")
    print(f"  –î–æ –æ—á–∏—Å—Ç–∫–∏: {total_original:,} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"  –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {total_cleaned:,} —Å–∏–º–≤–æ–ª–æ–≤")
    if total_original > 0:
        reduction = (total_original - total_cleaned) / total_original * 100
        print(f"  –£–¥–∞–ª–µ–Ω–æ: {reduction:.1f}% –º—É—Å–æ—Ä–∞")
    
    # 5. –°–æ–∑–¥–∞—ë–º –æ—Ç—á—ë—Ç
    report = {
        'total_files': len(txt_files),
        'processed_files': processed_count,
        'total_original_chars': total_original,
        'total_cleaned_chars': total_cleaned,
        'reduction_percent': reduction if total_original > 0 else 0,
        'timestamp': __import__('datetime').datetime.now().isoformat(),
    }
    
    report_path = cases_path / "cleaning_report.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nüìÑ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {report_path}")
    
    # 6. –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    if processed_count > 0:
        print(f"\nüîç –ü—Ä–∏–º–µ—Ä –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞:")
        sample_file = txt_files[0]
        with open(sample_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        if '=== –°–û–î–ï–†–ñ–ê–ù–ò–ï ===' in content:
            _, sample_content = content.split('=== –°–û–î–ï–†–ñ–ê–ù–ò–ï ===', 1)
            print("\n" + "="*40)
            print("–ü–ï–†–í–´–ï 500 –°–ò–ú–í–û–õ–û–í:")
            print("="*40)
            print(sample_content[:500] + "...")
            print("="*40)

def quick_clean_single_file(file_path: str):
    """
    –ë—ã—Å—Ç—Ä–∞—è –æ—á–∏—Å—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
    """
    path = Path(file_path)
    if not path.exists():
        print(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        return
    
    success, orig_len, cleaned_len = process_ecg_case_file(path)
    if success:
        print(f"\n‚úÖ –§–∞–π–ª –æ—á–∏—â–µ–Ω: {path.name}")
        print(f"   –ë—ã–ª–æ: {orig_len:,} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –°—Ç–∞–ª–æ: {cleaned_len:,} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –£–¥–∞–ª–µ–Ω–æ: {(orig_len - cleaned_len)/orig_len*100:.1f}%")
    else:
        print(f"\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å —Ñ–∞–π–ª")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        # –û—á–∏—Å—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        quick_clean_single_file(sys.argv[1])
    else:
        # –û—á–∏—Å—Ç–∫–∞ –≤—Å–µ–π –ø–∞–ø–∫–∏ Cases
        main()