import re
from pathlib import Path
import json

def clean_medical_article(content):
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π —Å—Ç–∞—Ç—å–∏.
    –û—Å—Ç–∞–≤–ª—è–µ—Ç –º–∞–∫—Å–∏–º—É–º –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞, —É–¥–∞–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ —è–≤–Ω—ã–π –º—É—Å–æ—Ä.
    """
    
    original_length = len(content)
    print(f"  –ù–∞—á–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {original_length} chars")
    
    # 1. –£–¥–∞–ª—è–µ–º –û–ß–ï–ù–¨ –û–°–¢–û–†–û–ñ–ù–û - —Ç–æ–ª—å–∫–æ —è–≤–Ω—ã–π –º—É—Å–æ—Ä –ü–û–°–õ–ï References
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —á–∞—Å—Ç–∏ –î–û –∏ –ü–û–°–õ–ï References
    if 'References' in content:
        # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ References
        ref_matches = list(re.finditer(r'References\d*\.', content))
        if ref_matches:
            last_ref = ref_matches[-1]
            # –í—Å—ë –î–û –ø–æ—Å–ª–µ–¥–Ω–∏—Ö References - –æ—Å—Ç–∞–≤–ª—è–µ–º
            main_content = content[:last_ref.end()]
            
            # –í—Å—ë –ü–û–°–õ–ï References - –æ—á–∏—â–∞–µ–º –æ—Ç –º—É—Å–æ—Ä–∞
            after_refs = content[last_ref.end():]
            
            # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –û–ß–ï–ù–¨ —è–≤–Ω—ã–π –º—É—Å–æ—Ä –ø–æ—Å–ª–µ References
            trash_patterns = [
                r'Show all references.*',
                r'eLetters.*?Sign In to Submit',
                r'Information & Authors.*?Metrics & Citations',
                r'Get Access.*?Get Access',
                r'Login options.*?Login',
                r'Purchase Options.*?Checkout',
                r'Restore your content access.*',
                r'Advertisement.*?Advertisement',
                r'Submit a Response.*?CancelSubmit',
                r'Browse.*?Annals of Internal Medicine',
                r'Now Reading.*?Next__',
                r'This page is managed.*?Confirm My Choices',
                r'Shopping cart.*?Cart',
                r'Sign in.*?REGISTER',
            ]
            
            for pattern in trash_patterns:
                after_refs = re.sub(pattern, '', after_refs, flags=re.DOTALL | re.IGNORECASE)
            
            # –°–æ–±–∏—Ä–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ
            content = main_content + after_refs
    
    # 2. –£–±–∏—Ä–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–æ–º–µ—Ç–∫–∏ –≤ —Å—Å—ã–ª–∫–∞—Ö, –Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º —Å–∞–º–∏ —Å—Å—ã–ª–∫–∏
    # –í–º–µ—Å—Ç–æ —É–¥–∞–ª–µ–Ω–∏—è "CrossrefPubMedGoogle Scholar", –ø—Ä–æ—Å—Ç–æ –¥–µ–ª–∞–µ–º –∏—Ö –º–µ–Ω–µ–µ –∑–∞–º–µ—Ç–Ω—ã–º–∏
    content = re.sub(r'(Crossref|PubMed|Google Scholar)', '', content)
    
    # 3. –£–¥–∞–ª—è–µ–º "doi: 10.xxx" –Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É
    content = re.sub(r'doi: \d+\.\d+/\S+\s*', '', content)
    
    # 4. –£–¥–∞–ª—è–µ–º HTML/XML —Ç–µ–≥–∏ –µ—Å–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å
    content = re.sub(r'<[^>]+>', '', content)
    
    # 5. –û—á–∏—â–∞–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    content = re.sub(r'\n{3,}', '\n\n', content)
    content = re.sub(r'[ \t]{2,}', ' ', content)
    
    cleaned_length = len(content)
    print(f"  –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {cleaned_length} chars")
    print(f"  –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {cleaned_length/original_length*100:.1f}%")
    
    return content.strip()

def extract_medical_content_safely(content):
    """
    –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥: –∏–∑–≤–ª–µ–∫–∞–µ–º –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ —á–∞—Å—Ç–∏ –ø–æ —à–∞–±–ª–æ–Ω–∞–º
    """
    medical_parts = []
    
    # –ò—â–µ–º Abstract
    abstract_match = re.search(r'Abstract(.*?)(?=Graphical Abstract|Introduction|Methods|References|$)', 
                               content, re.DOTALL | re.IGNORECASE)
    if abstract_match:
        medical_parts.append("ABSTRACT:\n" + abstract_match.group(1).strip())
    
    # –ò—â–µ–º Introduction
    intro_match = re.search(r'Introduction(.*?)(?=Methods|Results|Discussion|References|$)', 
                            content, re.DOTALL | re.IGNORECASE)
    if intro_match:
        medical_parts.append("\nINTRODUCTION:\n" + intro_match.group(1).strip())
    
    # –ò—â–µ–º Methods
    methods_match = re.search(r'Methods(.*?)(?=Results|Discussion|Conclusion|References|$)', 
                              content, re.DOTALL | re.IGNORECASE)
    if methods_match:
        medical_parts.append("\nMETHODS:\n" + methods_match.group(1).strip())
    
    # –ò—â–µ–º Results
    results_match = re.search(r'Results(.*?)(?=Discussion|Conclusion|References|$)', 
                              content, re.DOTALL | re.IGNORECASE)
    if results_match:
        medical_parts.append("\nRESULTS:\n" + results_match.group(1).strip())
    
    # –ò—â–µ–º Discussion/Conclusion
    discussion_match = re.search(r'(Discussion|Conclusion)(.*?)(?=References|$)', 
                                 content, re.DOTALL | re.IGNORECASE)
    if discussion_match:
        medical_parts.append(f"\n{discussion_match.group(1).upper()}:\n" + discussion_match.group(2).strip())
    
    # –ò—â–µ–º References
    refs_match = re.search(r'References\d*\.(.*)', content, re.DOTALL)
    if refs_match:
        medical_parts.append("\nREFERENCES:\n" + refs_match.group(1).strip())
    
    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ö–æ—Ç—å —á—Ç–æ-—Ç–æ
    if medical_parts:
        return '\n\n'.join(medical_parts)
    
    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª (–ª—É—á—à–µ –º—É—Å–æ—Ä, —á–µ–º –Ω–∏—á–µ–≥–æ)
    return content

def process_article_file_safely(file_path):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –±—ç–∫–∞–ø–∞"""
    with open(file_path, 'r', encoding='utf-8') as f:
        full_content = f.read()
    
    if '=== –°–û–î–ï–†–ñ–ê–ù–ò–ï ===' not in full_content:
        return False
    
    # –°–æ–∑–¥–∞—ë–º –±—ç–∫–∞–ø –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    backup_path = file_path.with_suffix('.original.txt')
    if not backup_path.exists():
        with open(backup_path, 'w', encoding='utf-8') as f:
            f.write(full_content)
        print(f"  –°–æ–∑–¥–∞–Ω –±—ç–∫–∞–ø: {backup_path.name}")
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ –∫–æ–Ω—Ç–µ–Ω—Ç
    metadata_part, article_content = full_content.split('=== –°–û–î–ï–†–ñ–ê–ù–ò–ï ===', 1)
    
    print(f"\nüìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞: {file_path.name}")
    
    # –ú–µ—Ç–æ–¥ 1: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
    cleaned_content = clean_medical_article(article_content)
    
    # –ú–µ—Ç–æ–¥ 2: –ï—Å–ª–∏ –æ—á–∏—Å—Ç–∫–∞ —É–¥–∞–ª–∏–ª–∞ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ (>80%), –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ
    if len(cleaned_content) < len(article_content) * 0.2:  # –û—Å—Ç–∞–ª–æ—Å—å –º–µ–Ω—å—à–µ 20%
        print(f"  ‚ö†Ô∏è  –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —É–¥–∞–ª–µ–Ω–æ, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∫–æ–Ω—Ç–µ–Ω—Ç...")
        cleaned_content = extract_medical_content_safely(article_content)
    
    # –ï—Å–ª–∏ –í–°–Å –†–ê–í–ù–û –º–∞–ª–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (<10%), –æ—Å—Ç–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º
    if len(cleaned_content) < len(article_content) * 0.1:
        print(f"  ‚ùó –û—á–µ–Ω—å –º–∞–ª–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –æ—Å—Ç–∞–≤–ª—è—é –æ—Ä–∏–≥–∏–Ω–∞–ª —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º")
        cleaned_content = "‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –º–Ω–æ–≥–æ –Ω–µ-–º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞\n" + article_content
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∞–π–ª
    new_content = metadata_part + '=== –°–û–î–ï–†–ñ–ê–ù–ò–ï ===\n' + cleaned_content
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(new_content)
    
    return True

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Ñ–∞–π–ª—ã"""
    articles_path = Path("data/processed/cardiology/Articles")
    
    if not articles_path.exists():
        print("–ü–∞–ø–∫–∞ Articles –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return
    
    # –°–Ω–∞—á–∞–ª–∞ –Ω–∞–π–¥—ë–º –≤—Å–µ —Ñ–∞–π–ª—ã —Å warning
    warning_files = list(articles_path.glob("*.warning.txt"))
    print(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏: {len(warning_files)}")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã, —É –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å warning
    for warning_file in warning_files:
        original_file = warning_file.with_suffix('.txt')  # –£–±–∏—Ä–∞–µ–º .warning
        if original_file.exists():
            print(f"\n{'='*50}")
            print(f"–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: {original_file.name}")
            print('='*50)
            
            process_article_file_safely(original_file)
            
            # –£–¥–∞–ª—è–µ–º warning —Ñ–∞–π–ª –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            warning_file.unlink()
            print(f"  –£–¥–∞–ª—ë–Ω warning —Ñ–∞–π–ª")

if __name__ == "__main__":
    main()